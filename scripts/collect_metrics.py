#!/usr/bin/env python3
"""
Collect performance metrics from load test results and aggregate them.

This script reads JSON result files generated by the load tests and
creates a unified metrics file suitable for baseline tracking.
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime


def load_json_file(file_path: str) -> Optional[Dict[str, Any]]:
    """Load and parse a JSON file."""
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: File not found: {file_path}", file=sys.stderr)
        return None
    except json.JSONDecodeError as e:
        print(f"Warning: Invalid JSON in {file_path}: {e}", file=sys.stderr)
        return None


def extract_metrics(result_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """Extract performance metrics from test result data."""
    if not result_data or 'results' not in result_data:
        return None

    results = result_data['results']
    if not results or len(results) == 0:
        return None

    # Take the first result (assuming single test per file)
    result = results[0]

    return {
        'test_name': result.get('test_name', 'Unknown'),
        'protocol': result.get('protocol', 'unknown'),
        'latency': {
            'p50_ms': result.get('latency_ms', {}).get('p50', 0.0),
            'p95_ms': result.get('latency_ms', {}).get('p95', 0.0),
            'p99_ms': result.get('latency_ms', {}).get('p99', 0.0),
            'mean_ms': result.get('latency_ms', {}).get('mean', 0.0),
            'stddev_ms': result.get('latency_ms', {}).get('stddev', 0.0),
        },
        'throughput_msg_s': result.get('throughput_msg_s', 0.0),
        'bandwidth_mbps': result.get('bandwidth_mbps', 0.0),
        'memory': {
            'rss_mb': result.get('memory', {}).get('rss_mb', 0.0),
            'heap_mb': result.get('memory', {}).get('heap_mb', 0.0),
            'vm_mb': result.get('memory', {}).get('vm_mb', 0.0),
        },
        'platform': result.get('platform', 'unknown'),
        'compiler': result.get('compiler', 'unknown'),
    }


def collect_all_metrics(
    tcp_json: Optional[str],
    udp_json: Optional[str],
    websocket_json: Optional[str]
) -> Dict[str, Any]:
    """Collect metrics from all protocol test results."""
    metrics = {
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'protocols': {}
    }

    # Collect TCP metrics
    if tcp_json:
        tcp_data = load_json_file(tcp_json)
        tcp_metrics = extract_metrics(tcp_data) if tcp_data else None
        if tcp_metrics:
            metrics['protocols']['tcp'] = tcp_metrics

    # Collect UDP metrics
    if udp_json:
        udp_data = load_json_file(udp_json)
        udp_metrics = extract_metrics(udp_data) if udp_data else None
        if udp_metrics:
            metrics['protocols']['udp'] = udp_metrics

    # Collect WebSocket metrics
    if websocket_json:
        ws_data = load_json_file(websocket_json)
        ws_metrics = extract_metrics(ws_data) if ws_data else None
        if ws_metrics:
            metrics['protocols']['websocket'] = ws_metrics

    return metrics


def write_metrics(metrics: Dict[str, Any], output_path: str) -> bool:
    """Write metrics to JSON file."""
    try:
        with open(output_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        return True
    except IOError as e:
        print(f"Error: Failed to write metrics to {output_path}: {e}", file=sys.stderr)
        return False


def print_summary(metrics: Dict[str, Any]) -> None:
    """Print a summary of collected metrics."""
    print("\n" + "=" * 60)
    print("Performance Metrics Summary")
    print("=" * 60)
    print(f"Timestamp: {metrics['timestamp']}")
    print(f"Protocols: {len(metrics['protocols'])}")
    print()

    for protocol, data in metrics['protocols'].items():
        print(f"{protocol.upper()}:")
        print(f"  Throughput: {data['throughput_msg_s']:.2f} msg/s")
        print(f"  Latency P50: {data['latency']['p50_ms']:.3f} ms")
        print(f"  Latency P95: {data['latency']['p95_ms']:.3f} ms")
        print(f"  Latency P99: {data['latency']['p99_ms']:.3f} ms")
        print(f"  Memory RSS: {data['memory']['rss_mb']:.2f} MB")
        print()

    print("=" * 60 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description='Collect and aggregate network load test metrics'
    )
    parser.add_argument(
        '--tcp-json',
        type=str,
        help='Path to TCP load test results JSON file'
    )
    parser.add_argument(
        '--udp-json',
        type=str,
        help='Path to UDP load test results JSON file'
    )
    parser.add_argument(
        '--websocket-json',
        type=str,
        help='Path to WebSocket load test results JSON file'
    )
    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='Output path for aggregated metrics JSON file'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='Suppress summary output'
    )

    args = parser.parse_args()

    # Validate that at least one input is provided
    if not any([args.tcp_json, args.udp_json, args.websocket_json]):
        print("Error: At least one protocol JSON file must be specified", file=sys.stderr)
        return 1

    # Collect metrics
    metrics = collect_all_metrics(args.tcp_json, args.udp_json, args.websocket_json)

    # Check if any metrics were collected
    if not metrics['protocols']:
        print("Error: No valid metrics were collected", file=sys.stderr)
        return 1

    # Write output
    if not write_metrics(metrics, args.output):
        return 1

    # Print summary unless quiet mode
    if not args.quiet:
        print_summary(metrics)
        print(f"Metrics written to: {args.output}")

    return 0


if __name__ == '__main__':
    sys.exit(main())
